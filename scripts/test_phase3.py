"""
Test script for Phase 3 data pipeline components.

Tests database, scheduler, data collector, webhooks, validation, ETL, and pipeline.
"""

import sys
from pathlib import Path
from datetime import datetime

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def test_database():
    """Test database initialization and basic operations."""
    print("\n" + "=" * 70)
    print("TEST: Database Initialization")
    print("=" * 70)
    
    try:
        from src.bandit_ads.database import init_database
        from src.bandit_ads.db_helpers import create_campaign, get_campaign
        from src.bandit_ads.models import CampaignCreate
        
        # Initialize database
        db_manager = init_database(create_tables=True)
        print("‚úÖ Database initialized")
        
        # Test health check
        if db_manager.health_check():
            print("‚úÖ Database health check passed")
        else:
            print("‚ö†Ô∏è  Database health check failed")
        
        # Test creating a campaign
        campaign = create_campaign(CampaignCreate(
            name="Test Campaign",
            budget=1000.0,
            start_date=datetime.utcnow()
        ))
        print(f"‚úÖ Created campaign: {campaign.name} (ID: {campaign.id})")
        
        # Test retrieving campaign
        retrieved = get_campaign(campaign.id)
        if retrieved and retrieved.name == campaign.name:
            print(f"‚úÖ Retrieved campaign: {retrieved.name}")
        else:
            print("‚ö†Ô∏è  Failed to retrieve campaign")
        
        return True
    except Exception as e:
        print(f"‚ùå Database test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_scheduler():
    """Test scheduler functionality."""
    print("\n" + "=" * 70)
    print("TEST: Scheduler")
    print("=" * 70)
    
    try:
        from src.bandit_ads.scheduler import get_scheduler
        
        scheduler = get_scheduler()
        print("‚úÖ Scheduler created")
        
        # Test adding a job
        def test_job():
            return "test completed"
        
        job_id = scheduler.add_interval_job(
            func=test_job,
            job_id='test_job',
            seconds=60
        )
        print(f"‚úÖ Added test job: {job_id}")
        
        # Test listing jobs (scheduler needs to be running)
        try:
            scheduler.start()
            jobs = scheduler.list_jobs()
            print(f"‚úÖ Listed {len(jobs)} jobs")
            scheduler.stop()
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not list jobs (scheduler may need to be running): {str(e)}")
        
        # Clean up
        scheduler.remove_job('test_job')
        print("‚úÖ Removed test job")
        
        return True
    except Exception as e:
        print(f"‚ùå Scheduler test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_data_validator():
    """Test data validation."""
    print("\n" + "=" * 70)
    print("TEST: Data Validator")
    print("=" * 70)
    
    try:
        from src.bandit_ads.data_validator import DataValidator, validate_and_clean_metric
        from src.bandit_ads.models import MetricCreate
        
        validator = DataValidator()
        print("‚úÖ Data validator created")
        
        # Test valid metric
        valid_metric = MetricCreate(
            campaign_id=1,
            arm_id=1,
            timestamp=datetime.utcnow(),
            impressions=1000,
            clicks=50,
            conversions=5,
            revenue=100.0,
            cost=50.0
        )
        
        is_valid, cleaned, warnings = validate_and_clean_metric(valid_metric, validator)
        if is_valid:
            print("‚úÖ Valid metric passed validation")
        else:
            print(f"‚ö†Ô∏è  Valid metric failed validation: {warnings}")
        
        # Test invalid metric (Pydantic will validate before we can call validate_and_clean_metric)
        try:
            invalid_metric = MetricCreate(
                campaign_id=1,
                arm_id=1,
                timestamp=datetime.utcnow(),
                impressions=100,
                clicks=150,  # More clicks than impressions - invalid
                conversions=5,
                revenue=100.0,
                cost=50.0
            )
            print("‚ö†Ô∏è  Invalid metric was not rejected by Pydantic")
        except Exception as e:
            # Pydantic validation caught it
            print(f"‚úÖ Invalid metric correctly rejected by Pydantic validation")
        
        return True
    except Exception as e:
        print(f"‚ùå Data validator test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_etl_pipeline():
    """Test ETL pipeline."""
    print("\n" + "=" * 70)
    print("TEST: ETL Pipeline")
    print("=" * 70)
    
    try:
        from src.bandit_ads.etl import ETLPipeline
        
        etl = ETLPipeline(lookback_days=7)
        print("‚úÖ ETL pipeline created")
        
        # Test would require actual campaign data
        print("‚ÑπÔ∏è  ETL pipeline ready (requires campaign data to test)")
        
        return True
    except Exception as e:
        print(f"‚ùå ETL pipeline test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def test_pipeline_manager():
    """Test pipeline manager."""
    print("\n" + "=" * 70)
    print("TEST: Pipeline Manager")
    print("=" * 70)
    
    try:
        from src.bandit_ads.pipeline import PipelineManager, PipelineJob
        from src.bandit_ads.utils import ConfigManager
        
        config_manager = ConfigManager()
        manager = PipelineManager(config_manager)
        print("‚úÖ Pipeline manager created")
        
        # Test health check
        health = manager.get_pipeline_health()
        print(f"‚úÖ Pipeline health: {health['status']}")
        
        # Test metrics
        try:
            metrics = manager.get_pipeline_metrics()
            print(f"‚úÖ Pipeline metrics: {metrics['total_jobs']} jobs registered")
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not get metrics: {str(e)}")
        
        return True
    except Exception as e:
        print(f"‚ùå Pipeline manager test failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Run all Phase 3 tests."""
    print("\n" + "=" * 70)
    print("PHASE 3 DATA PIPELINE - TEST SUITE")
    print("=" * 70)
    print("\nNote: Some tests require dependencies to be installed:")
    print("  pip install sqlalchemy apscheduler flask pydantic")
    
    results = {
        'database': test_database(),
        'scheduler': test_scheduler(),
        'data_validator': test_data_validator(),
        'etl_pipeline': test_etl_pipeline(),
        'pipeline_manager': test_pipeline_manager()
    }
    
    print("\n" + "=" * 70)
    print("TEST RESULTS")
    print("=" * 70)
    
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    for test_name, result in results.items():
        status = "‚úÖ PASSED" if result else "‚ùå FAILED"
        print(f"{test_name:20s}: {status}")
    
    print(f"\nTotal: {passed}/{total} tests passed")
    
    if passed == total:
        print("\nüéâ All Phase 3 tests passed!")
    else:
        print("\n‚ö†Ô∏è  Some tests failed. Check errors above.")
    
    return 0 if passed == total else 1


if __name__ == "__main__":
    exit(main())
